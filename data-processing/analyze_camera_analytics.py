#!/usr/bin/env python3
"""
Generate analytics PDF from camera test summary CSV.

This script reads the summary.csv file generated by plot_test_data.py and creates
a comprehensive PDF report with plots of image means grouped by aperture size and position.

Usage:
    python analyze_camera_analytics.py <summary_csv_path>

Arguments:
    summary_csv_path: Path to the summary.csv file (e.g., qisda_data/output/summary.csv)
"""

import sys
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.backends.backend_pdf
import numpy as np
import re
from pathlib import Path

    
kurtosis_threshold = 1
skewness_threshold = 0.2

def extract_aperture_size(relative_path):
    """
    Extract aperture size from relative path.
    Looks for patterns like "3mm", "1.5mm", "0.75mm", etc.
    
    Args:
        relative_path (str): Relative path string
        
    Returns:
        str: Aperture size (e.g., "3mm", "1.5mm", "0.75mm") or "Unknown"
    """
    if pd.isna(relative_path):
        return "Unknown"
    
    # Look for patterns like Xmm, X.Xmm, X.XXmm in the path
    # Pattern: digits, optional decimal point, more digits, then "mm"
    match = re.search(r'(\d+\.?\d*)mm', str(relative_path))
    if match:
        return match.group(1) + "mm"
    
    return "Unknown"


def load_and_prepare_data(csv_path):
    """
    Load the summary CSV and add aperture size column.
    
    Args:
        csv_path (str): Path to summary.csv
        
    Returns:
        pd.DataFrame: DataFrame with aperture_size column added
    """
    df = pd.read_csv(csv_path)
    
    # Extract aperture size from relative_path
    df['aperture_size'] = df['relative_path'].apply(extract_aperture_size)
    
    # Convert position from 0-indexed to 1-indexed for display
    df['position_1indexed'] = df['position'] + 1
    
    # Filter to only light histograms for mean analysis (as requested)
    # Or we can include both - let's include both but separate them
    df_light = df[df['histogram_type'] == 'light'].copy()
    df_dark = df[df['histogram_type'] == 'dark'].copy()
    
    return df, df_light, df_dark


def plot_means_by_aperture_and_position(df_light, df_dark, ax):
    """
    Create grouped bar chart of means by aperture and position.
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        df_dark (pd.DataFrame): Dark histogram data
        ax: Matplotlib axis
    """
    # Group by aperture and position
    light_means = df_light.groupby(['aperture_size', 'position'])['weighted_mean'].mean().reset_index()
    dark_means = df_dark.groupby(['aperture_size', 'position'])['weighted_mean'].mean().reset_index()
    
    # Get unique apertures and positions (combine from both light and dark)
    apertures = sorted(set(df_light['aperture_size'].unique()) | set(df_dark['aperture_size'].unique()))
    positions = sorted(set(df_light['position'].unique()) | set(df_dark['position'].unique()))
    positions_1indexed = [p + 1 for p in positions]  # Convert to 1-indexed for display
    
    x = np.arange(len(positions))
    # Each aperture gets 2 bars (light + dark), so total width per position group
    # should accommodate all aperture pairs with some spacing
    n_bars_per_position = len(apertures) * 2  # 2 bars (light/dark) per aperture
    total_width = 0.8  # Total width available per position group
    bar_width = total_width / n_bars_per_position
    
    # Calculate starting offset for each position group to center all bars
    group_width = n_bars_per_position * bar_width
    start_offset = -group_width / 2 + bar_width / 2
    
    # Plot bars for each aperture
    for i, aperture in enumerate(apertures):
        light_vals = []
        dark_vals = []
        for pos in positions:
            light_val = light_means[(light_means['aperture_size'] == aperture) & 
                                   (light_means['position'] == pos)]['weighted_mean']
            dark_val = dark_means[(dark_means['aperture_size'] == aperture) & 
                                 (dark_means['position'] == pos)]['weighted_mean']
            light_vals.append(light_val.values[0] if len(light_val) > 0 else np.nan)
            dark_vals.append(dark_val.values[0] if len(dark_val) > 0 else np.nan)
        
        # Calculate x positions for this aperture's bars
        # Each aperture gets 2 consecutive bars (light, then dark)
        aperture_offset = i * 2 * bar_width  # Offset for this aperture's pair of bars
        light_x = x + start_offset + aperture_offset
        dark_x = x + start_offset + aperture_offset + bar_width
        
        ax.bar(light_x, light_vals, bar_width, label=f'{aperture} Light', alpha=0.8)
        ax.bar(dark_x, dark_vals, bar_width, label=f'{aperture} Dark', alpha=0.8)
    
    ax.set_xlabel('Position (cam_id)', fontsize=10)
    ax.set_ylabel('Weighted Mean', fontsize=10)
    ax.set_title('Mean Weighted Values by Aperture Size and Position', fontsize=12, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(positions_1indexed)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax.grid(True, alpha=0.3, axis='y')


def plot_boxplot_by_aperture(df_light, df_dark, ax):
    """
    Create horizontal box plot of means grouped by aperture size (light histograms only).
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        df_dark (pd.DataFrame): Dark histogram data (not used, kept for API compatibility)
        ax: Matplotlib axis
    """
    # Light histograms only
    data_to_plot = []
    labels = []
    
    apertures = sorted(df_light['aperture_size'].unique())
    
    for aperture in apertures:
        light_data = df_light[df_light['aperture_size'] == aperture]['weighted_mean'].values
        
        if len(light_data) > 0:
            data_to_plot.append(light_data)
            labels.append(f'{aperture}')
    
    bp = ax.boxplot(data_to_plot, tick_labels=labels, patch_artist=True, vert=False)
    
    # Color the boxes
    colors = plt.cm.Set3(np.linspace(0, 1, len(bp['boxes'])))
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    # Add data point markers with jitter
    for i, data in enumerate(data_to_plot):
        # For horizontal boxplots, y-position is the box number (1-indexed), add jitter
        y_pos = i + 1
        y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
        ax.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
    
    ax.set_xlabel('Weighted Mean', fontsize=10)
    ax.set_ylabel('Aperture Size', fontsize=10)
    ax.set_title('Distribution of Means by Aperture Size (Light)', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')


def plot_boxplot_by_aperture_dark(df_light, df_dark, ax):
    """
    Create horizontal box plot of means grouped by aperture size (dark histograms only).
    
    Args:
        df_light (pd.DataFrame): Light histogram data (not used, kept for API compatibility)
        df_dark (pd.DataFrame): Dark histogram data
        ax: Matplotlib axis
    """
    # Dark histograms only
    data_to_plot = []
    labels = []
    
    apertures = sorted(df_dark['aperture_size'].unique())
    
    for aperture in apertures:
        dark_data = df_dark[df_dark['aperture_size'] == aperture]['weighted_mean'].values
        
        if len(dark_data) > 0:
            data_to_plot.append(dark_data)
            labels.append(f'{aperture}')
    
    bp = ax.boxplot(data_to_plot, tick_labels=labels, patch_artist=True, vert=False)
    
    # Color the boxes (using red tones for dark histograms)
    colors = plt.cm.Reds(np.linspace(0.4, 0.8, len(bp['boxes'])))
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    # Add data point markers with jitter
    for i, data in enumerate(data_to_plot):
        # For horizontal boxplots, y-position is the box number (1-indexed), add jitter
        y_pos = i + 1
        y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
        ax.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
    
    ax.set_xlabel('Weighted Mean', fontsize=10)
    ax.set_ylabel('Aperture Size', fontsize=10)
    ax.set_title('Distribution of Means by Aperture Size (Dark)', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')


def plot_boxplot_by_position(df_light, df_dark, ax):
    """
    Create box plot of means grouped by position (cam_id).
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        df_dark (pd.DataFrame): Dark histogram data
        ax: Matplotlib axis
    """
    # Combine light and dark for box plot
    data_to_plot = []
    labels = []
    
    positions = sorted(df_light['position'].unique())
    
    for pos in positions:
        light_data = df_light[df_light['position'] == pos]['weighted_mean'].values
        dark_data = df_dark[df_dark['position'] == pos]['weighted_mean'].values
        
        if len(light_data) > 0:
            data_to_plot.append(light_data)
            labels.append(f'Pos {pos + 1}\nLight')  # 1-indexed
        
        if len(dark_data) > 0:
            data_to_plot.append(dark_data)
            labels.append(f'Pos {pos + 1}\nDark')  # 1-indexed
    
    bp = ax.boxplot(data_to_plot, tick_labels=labels, patch_artist=True)
    
    # Color the boxes
    colors = plt.cm.Set2(np.linspace(0, 1, len(bp['boxes'])))
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    # Add data point markers with jitter
    for i, data in enumerate(data_to_plot):
        # For vertical boxplots, x-position is the box number (1-indexed), add jitter
        x_pos = i + 1
        x_jittered = x_pos + np.random.normal(0, 0.05, size=len(data))
        ax.scatter(x_jittered, data, c='black', alpha=0.5, s=20, zorder=3)
    
    ax.set_ylabel('Weighted Mean', fontsize=10)
    ax.set_title('Distribution of Means by Position (cam_id)', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='y')
    ax.tick_params(axis='x', rotation=45)
    for label in ax.get_xticklabels():
        label.set_ha('right')


def plot_scatter_aperture_vs_mean(df_light, df_dark, ax):
    """
    Create horizontal boxplot of means grouped by position (light and dark combined).
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        df_dark (pd.DataFrame): Dark histogram data
        ax: Matplotlib axis
    """
    # Combine light and dark for box plot grouped by position
    data_to_plot = []
    labels = []
    
    positions = sorted(df_light['position'].unique())
    
    for pos in positions:
        # Combine light and dark data for this position
        light_data = df_light[df_light['position'] == pos]['weighted_mean'].values
        dark_data = df_dark[df_dark['position'] == pos]['weighted_mean'].values
        
        # Combine both datasets for this position
        combined_data = np.concatenate([light_data, dark_data])
        
        if len(combined_data) > 0:
            data_to_plot.append(combined_data)
            labels.append(f'Pos {pos + 1}')  # 1-indexed
    
    # Create horizontal boxplot
    bp = ax.boxplot(data_to_plot, tick_labels=labels, patch_artist=True, vert=False)
    
    # Use a single color scheme (no color coding by position)
    color = '#4A90E2'  # Single blue color
    for patch in bp['boxes']:
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    # Add data point markers with jitter
    for i, data in enumerate(data_to_plot):
        # For horizontal boxplots, y-position is the box number (1-indexed), add jitter
        y_pos = i + 1
        y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
        ax.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
    
    ax.set_xlabel('Weighted Mean', fontsize=10)
    ax.set_ylabel('Position (cam_id)', fontsize=10)
    ax.set_title('Mean vs Aperture Size by Position', fontsize=12, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')


def detect_boxplot_outliers(df_light):
    """
    Detect outliers from light histograms using boxplot statistics (IQR method).
    Outliers are detected per aperture size AND position combination.
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        
    Returns:
        list: List of outlier dictionaries with all metadata
    """
    outliers = []
    
    # Process each aperture size AND position combination separately
    for aperture in sorted(df_light['aperture_size'].unique()):
        if aperture == "Unknown":
            continue
        
        aperture_data = df_light[df_light['aperture_size'] == aperture].copy()
        
        # Process each position within this aperture size
        for position in sorted(aperture_data['position'].unique()):
            position_data = aperture_data[aperture_data['position'] == position].copy()
            
            if len(position_data) < 4:  # Need at least 4 points for meaningful boxplot
                continue
            
            # Calculate boxplot statistics for this aperture + position combination
            Q1 = np.percentile(position_data['weighted_mean'], 25)
            Q3 = np.percentile(position_data['weighted_mean'], 75)
            IQR = Q3 - Q1
            
            # Calculate whisker bounds (standard boxplot: 1.5 * IQR)
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # Find outliers
            outlier_mask = (position_data['weighted_mean'] < lower_bound) | (position_data['weighted_mean'] > upper_bound)
            outlier_rows = position_data[outlier_mask]
            
            # Store outlier information
            for _, row in outlier_rows.iterrows():
                outlier_type = "High" if row['weighted_mean'] > upper_bound else "Low"
                outliers.append({
                    'serial_number': row['serial_number'],
                    'aperture_size': aperture,
                    'position': row['position'] + 1,  # 1-indexed
                    'weighted_mean': row['weighted_mean'],
                    'temperature': row['temperature'],
                    'relative_path': row['relative_path'],
                    'filename': row['filename'],
                    'outlier_type': outlier_type,
                    'lower_bound': lower_bound,
                    'upper_bound': upper_bound
                })
    
    return outliers


def detect_non_normal_histograms(df_light, csv_base_path):
    """
    Detect light histograms that deviate from a normal distribution.
    Uses multiple criteria: multiple peaks, skewness, kurtosis, and secondary humps.
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        csv_base_path (Path): Base path to the CSV file (for resolving relative paths)
        
    Returns:
        list: List of non-normal histogram dictionaries with all metadata
    """
    non_normal_histograms = []
    
    for _, row in df_light.iterrows():
        # Resolve file path
        relative_path = row['relative_path']
        relative_path_str = str(relative_path).replace('\\', '/')
        file_path = csv_base_path.parent.parent / relative_path_str
        
        # Load histogram
        hist_values, temp, cam_id = load_histogram_from_csv(file_path)
        
        if hist_values is None:
            continue
        
        # Check if histogram deviates from normal
        is_non_normal, num_peaks, peak_positions, reasons, skewness, kurtosis = check_non_normal(hist_values)
        
        if is_non_normal:
            non_normal_histograms.append({
                'serial_number': row['serial_number'],
                'aperture_size': row['aperture_size'],
                'position': row['position'] + 1,  # 1-indexed
                'weighted_mean': row['weighted_mean'],
                'temperature': row['temperature'],
                'relative_path': row['relative_path'],
                'filename': row['filename'],
                'num_peaks': num_peaks,
                'peak_positions': peak_positions,
                'reasons': reasons,
                'skewness': skewness,
                'kurtosis': kurtosis
            })
    
    return non_normal_histograms


def find_peaks_simple(signal, height=None, distance=None, prominence=None):
    """
    Simple peak detection algorithm using numpy only.
    Finds local maxima that meet height, distance, and prominence criteria.
    
    Args:
        signal (array): Input signal
        height (float): Minimum height of peaks
        distance (int): Minimum distance between peaks
        prominence (float): Minimum prominence of peaks
        
    Returns:
        tuple: (peaks: array, properties: dict)
    """
    signal = np.array(signal)
    
    # Find local maxima (peaks)
    # A point is a peak if it's greater than its neighbors
    peaks = []
    for i in range(1, len(signal) - 1):
        if signal[i] > signal[i-1] and signal[i] > signal[i+1]:
            peaks.append(i)
    
    if len(peaks) == 0:
        return np.array([]), {}
    
    peaks = np.array(peaks)
    
    # Filter by height
    if height is not None:
        peak_heights = signal[peaks]
        peaks = peaks[peak_heights >= height]
    
    if len(peaks) == 0:
        return np.array([]), {}
    
    # Filter by distance (keep only peaks that are far enough apart)
    if distance is not None and len(peaks) > 1:
        filtered_peaks = [peaks[0]]
        for peak in peaks[1:]:
            if peak - filtered_peaks[-1] >= distance:
                filtered_peaks.append(peak)
        peaks = np.array(filtered_peaks)
    
    # Filter by prominence
    # Prominence is the height of the peak above the higher of the two surrounding minima
    if prominence is not None and len(peaks) > 0:
        filtered_peaks = []
        for peak in peaks:
            peak_val = signal[peak]
            
            # Find minimum on left side (up to previous peak or start)
            left_min = np.min(signal[:peak+1]) if peak > 0 else peak_val
            
            # Find minimum on right side (up to next peak or end)
            right_min = np.min(signal[peak:]) if peak < len(signal) - 1 else peak_val
            
            # Prominence is peak height minus the higher of the two surrounding minima
            surrounding_min = max(left_min, right_min)
            peak_prominence = peak_val - surrounding_min
            
            if peak_prominence >= prominence:
                filtered_peaks.append(peak)
        
        peaks = np.array(filtered_peaks)
    
    properties = {'peak_heights': signal[peaks] if len(peaks) > 0 else np.array([])}
    return peaks, properties


def calculate_skewness(histogram_values):
    """
    Calculate skewness of a distribution.
    Normal distributions have skewness ≈ 0.
    
    Args:
        histogram_values (array): Histogram bin values
        
    Returns:
        float: Skewness value
    """
    # Create weighted distribution
    bins = np.arange(len(histogram_values))
    total = np.sum(histogram_values)
    if total == 0:
        return 0.0
    
    # Calculate weighted mean
    mean = np.sum(bins * histogram_values) / total
    
    # Calculate weighted variance
    variance = np.sum(histogram_values * (bins - mean) ** 2) / total
    
    if variance == 0:
        return 0.0
    
    std = np.sqrt(variance)
    
    # Calculate skewness (third moment)
    skewness = np.sum(histogram_values * ((bins - mean) / std) ** 3) / total
    
    return skewness


def calculate_kurtosis(histogram_values):
    """
    Calculate kurtosis of a distribution.
    Normal distributions have kurtosis ≈ 3 (excess kurtosis ≈ 0).
    
    Args:
        histogram_values (array): Histogram bin values
        
    Returns:
        float: Kurtosis value
    """
    # Create weighted distribution
    bins = np.arange(len(histogram_values))
    total = np.sum(histogram_values)
    if total == 0:
        return 3.0  # Normal distribution kurtosis
    
    # Calculate weighted mean and std
    mean = np.sum(bins * histogram_values) / total
    variance = np.sum(histogram_values * (bins - mean) ** 2) / total
    
    if variance == 0:
        return 3.0
    
    std = np.sqrt(variance)
    
    # Calculate kurtosis (fourth moment)
    kurtosis = np.sum(histogram_values * ((bins - mean) / std) ** 4) / total
    
    return kurtosis


def detect_secondary_hump(histogram_values, max_position):
    """
    Detect if there's a secondary hump/shoulder in the distribution,
    even without a clear peak. This catches cases where there's a
    second hump that doesn't form a distinct peak.
    
    Args:
        histogram_values (array): Histogram bin values
        max_position (int): Position of the main peak
        
    Returns:
        tuple: (has_secondary_hump: bool, hump_position: int or None)
    """
    # Smooth the histogram
    window_size = 5
    if len(histogram_values) > window_size:
        smoothed = np.convolve(histogram_values, np.ones(window_size)/window_size, mode='same')
    else:
        smoothed = histogram_values
    
    max_value = np.max(smoothed)
    if max_value == 0:
        return False, None
    
    # Find the main peak region (around max_position)
    # Look for a secondary hump on the other side of the distribution
    # A hump is a region where values are significantly elevated
    
    # Split the distribution into left and right halves relative to the main peak
    left_side = smoothed[:max_position]
    right_side = smoothed[max_position+1:]
    
    # Threshold for significant elevation: at least 15% of max value
    threshold = max_value * 0.15
    
    # Check left side for secondary hump
    if len(left_side) > 50:
        # Find the maximum in the left half (excluding the edge near main peak)
        left_half = left_side[:len(left_side)//2]
        if len(left_half) > 0:
            left_max_idx_in_half = np.argmax(left_half)
            left_max_val = left_half[left_max_idx_in_half]
            if left_max_val >= threshold:
                # Check if this is a distinct hump (not just noise)
                # Look for a region around this max that's elevated
                region_start = max(0, left_max_idx_in_half - 20)
                region_end = min(len(left_half), left_max_idx_in_half + 20)
                region_avg = np.mean(left_half[region_start:region_end])
                if region_avg >= threshold * 0.7:
                    # Return absolute position in the full array
                    # left_max_idx_in_half is relative to left_half, which starts at index 0
                    # left_half is the first half of left_side, which starts at index 0
                    # left_side is [:max_position], so absolute position is just left_max_idx_in_half
                    return True, left_max_idx_in_half
    
    # Check right side for secondary hump
    if len(right_side) > 50:
        # Find the maximum in the right half (excluding the edge near main peak)
        right_half = right_side[len(right_side)//2:]
        if len(right_half) > 0:
            right_max_idx_in_half = np.argmax(right_half)
            right_max_idx = len(right_side)//2 + right_max_idx_in_half
            right_max_val = right_half[right_max_idx_in_half]
            if right_max_val >= threshold:
                # Check if this is a distinct hump
                region_start = max(0, right_max_idx_in_half - 20)
                region_end = min(len(right_half), right_max_idx_in_half + 20)
                region_avg = np.mean(right_half[region_start:region_end])
                if region_avg >= threshold * 0.7:
                    return True, max_position + 1 + right_max_idx
    
    return False, None


def check_non_normal(histogram_values):
    """
    Check if a histogram deviates from a normal distribution.
    Uses multiple criteria:
    1. Multiple peaks (bimodal/multimodal)
    2. High skewness (asymmetry)
    3. Abnormal kurtosis (tail heaviness)
    4. Secondary humps/shoulders
    
    Args:
        histogram_values (array): Histogram bin values
        
    Returns:
        tuple: (is_non_normal: bool, num_peaks: int, peak_positions: list, 
                reasons: list, skewness: float, kurtosis: float)
    """
    reasons = []
    
    # Smooth the histogram slightly to reduce noise
    window_size = 5
    if len(histogram_values) > window_size:
        smoothed = np.convolve(histogram_values, np.ones(window_size)/window_size, mode='same')
    else:
        smoothed = histogram_values
    
    max_value = np.max(smoothed)
    if max_value == 0:
        return False, 0, [], [], 0.0, 3.0
    
    max_position = np.argmax(smoothed)
    
    # 1. Check for multiple peaks (bimodal/multimodal)
    peaks, properties = find_peaks_simple(smoothed, 
                                         height=max_value * 0.05,  # At least 5% of max
                                         distance=50,              # At least 50 bins apart
                                         prominence=max_value * 0.08)  # Lower prominence to catch more cases
    
    num_peaks = len(peaks)
    peak_positions = peaks.tolist()
    
    if num_peaks >= 2:
        reasons.append(f"Multiple peaks ({num_peaks})")

    # 2. Check for skewness (normal distribution should have skewness ≈ 0)
    skewness = calculate_skewness(histogram_values)
    if abs(skewness) > skewness_threshold:  # Significant skewness
        reasons.append(f"High skewness ({skewness:.2f})")
    
    # 3. Check for kurtosis (normal distribution should have kurtosis ≈ 3)
    kurtosis = calculate_kurtosis(histogram_values)
    excess_kurtosis = kurtosis - 3.0
    if abs(excess_kurtosis) > kurtosis_threshold:  # Significant deviation from normal
        reasons.append(f"Abnormal kurtosis ({kurtosis:.2f})")
    
    # 4. Check for secondary humps/shoulders
    has_secondary_hump, hump_position = detect_secondary_hump(histogram_values, max_position)
    if has_secondary_hump:
        reasons.append("Secondary hump detected")
        if hump_position is not None and hump_position not in peak_positions:
            peak_positions.append(hump_position)
            peak_positions.sort()
            num_peaks = len(peak_positions)
    
    # Consider it non-normal if it fails any criterion
    is_non_normal = len(reasons) > 0
    
    return is_non_normal, num_peaks, peak_positions, reasons, skewness, kurtosis


def load_histogram_from_csv(filepath):
    """
    Load histogram data from CSV file.
    
    Args:
        filepath (Path): Path to the CSV file
        
    Returns:
        tuple: (histogram_values, temperature, cam_id) or (None, None, None) if error
    """
    try:
        df = pd.read_csv(filepath)
        
        # Extract histogram data (columns 0 to 1023, which are bins 0-1023)
        histogram_cols = [str(i) for i in range(1024)]
        histogram_values = df[histogram_cols].iloc[0].values
        
        # Extract temperature
        temperature = df['temperature'].iloc[0]
        
        # Extract cam_id (position)
        cam_id = df['cam_id'].iloc[0]
        
        return histogram_values, temperature, cam_id
        
    except Exception as e:
        print(f"Error loading histogram from {filepath}: {e}")
        return None, None, None


def plot_histogram(histogram_values, ax, title, temperature, cam_id, weighted_mean):
    """
    Plot a single histogram.
    
    Args:
        histogram_values (array): Histogram bin values
        ax: Matplotlib axis
        title (str): Plot title
        temperature (float): Temperature value
        cam_id (int): Camera position
        weighted_mean (float): Weighted mean value
    """
    bins = np.arange(1024)
    
    # Handle log scale - add small value to avoid log(0)
    hist_log = histogram_values + 1e-6
    
    # Plot histogram
    ax.semilogy(bins, hist_log, 'b-', linewidth=1.5, alpha=0.8)
    ax.fill_between(bins, hist_log, alpha=0.3, color='blue')
    
    ax.set_xlabel('Pixel Value (Bin)', fontsize=10)
    ax.set_ylabel('Count (Log Scale)', fontsize=10)
    ax.set_title(title, fontsize=11, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, 1023)
    ax.set_ylim(bottom=1.0)
    
    # Add text with stats
    stats_text = f'Mean: {weighted_mean:.1f}, Temp: {temperature:.1f}°C, Pos: {cam_id + 1}'
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
           fontsize=9, verticalalignment='top',
           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))


def create_outlier_summary_and_plots(df_light, csv_base_path, pdf):
    """
    Create outlier summary page and individual histogram plots for each outlier.
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        csv_base_path (Path): Base path to the CSV file (for resolving relative paths)
        pdf: PDF pages object
    """
    # Find outliers
    outliers = detect_boxplot_outliers(df_light)
    
    if len(outliers) == 0:
        # Create a page saying no outliers
        fig = plt.figure(figsize=(11, 8.5))
        fig.suptitle('Outlier Analysis - Light Histograms', fontsize=16, fontweight='bold', y=0.98)
        ax = fig.add_subplot(1, 1, 1)
        ax.axis('off')
        ax.text(0.5, 0.5, 'No outliers detected in light histograms!', 
               fontsize=14, ha='center', va='center',
               transform=ax.transAxes, 
               bbox=dict(boxstyle='round', facecolor='#90EE90', alpha=0.5))
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()
        return
    
    # Create summary page
    fig = plt.figure(figsize=(11, 8.5))
    fig.suptitle('Outlier Summary - Light Histograms', fontsize=16, fontweight='bold', y=0.98)
    
    # Summary table
    ax_table = fig.add_subplot(1, 1, 1)
    ax_table.axis('off')
    
    # Prepare table data
    table_data = []
    for outlier in outliers:
        table_data.append([
            outlier['serial_number'],
            outlier['aperture_size'],
            str(outlier['position']),
            f"{outlier['weighted_mean']:.2f}",
            outlier['outlier_type'],
            f"{outlier['temperature']:.1f}"
        ])
    
    # Create table
    table = ax_table.table(cellText=table_data,
                          colLabels=['Serial Number', 'Aperture', 'Position', 'Weighted Mean', 'Type', 'Temp (°C)'],
                          cellLoc='center',
                          loc='center',
                          bbox=[0, 0, 1, 1])
    
    table.auto_set_font_size(False)
    table.set_fontsize(8)
    table.scale(1, 1.2)
    
    # Style the header
    for i in range(6):
        table[(0, i)].set_facecolor('#E74C3C')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    # Highlight rows by outlier type
    for i, outlier in enumerate(outliers, start=1):
        if outlier['outlier_type'] == "High":
            # Red for high outliers
            for j in range(6):
                table[(i, j)].set_facecolor('#FFE5E5')
        else:
            # Orange for low outliers
            for j in range(6):
                table[(i, j)].set_facecolor('#FFF4E5')
    
    ax_table.set_title(f'Outliers Detected: {len(outliers)}', fontsize=12, fontweight='bold', pad=20)
    
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Create individual histogram plots for each outlier
    for outlier in outliers:
        # Resolve file path
        # csv_base_path is the summary.csv file (e.g., qisda_data/output/summary.csv)
        # relative_path is relative to the folder passed to plot_test_data.py (e.g., qisda_data)
        # So if summary.csv is in qisda_data/output/, relative_path is relative to qisda_data/
        relative_path = outlier['relative_path']
        # Convert forward slashes to OS-appropriate separators if needed
        relative_path_str = str(relative_path).replace('\\', '/')
        # csv_base_path.parent.parent gets us from output/ to qisda_data/
        file_path = csv_base_path.parent.parent / relative_path_str
        
        # Load histogram
        hist_values, temp, cam_id = load_histogram_from_csv(file_path)
        
        if hist_values is None:
            # Create error page
            fig = plt.figure(figsize=(11, 8.5))
            fig.suptitle(f'Outlier: {outlier["serial_number"]} - {outlier["aperture_size"]}', 
                        fontsize=14, fontweight='bold')
            ax = fig.add_subplot(1, 1, 1)
            ax.axis('off')
            ax.text(0.5, 0.5, f'Error loading histogram:\n{file_path}', 
                   fontsize=12, ha='center', va='center',
                   transform=ax.transAxes)
            pdf.savefig(fig, bbox_inches='tight')
            plt.close()
            continue
        
        # Create histogram plot
        fig, ax = plt.subplots(figsize=(11, 8.5))
        title = f'Outlier: {outlier["serial_number"]} - {outlier["aperture_size"]} - Pos {outlier["position"]}'
        subtitle = f'Mean: {outlier["weighted_mean"]:.2f} ({outlier["outlier_type"]} outlier, Bounds: {outlier["lower_bound"]:.2f} - {outlier["upper_bound"]:.2f})'
        plot_histogram(hist_values, ax, f'{title}\n{subtitle}', 
                      temp, cam_id, outlier['weighted_mean'])
        
        fig.tight_layout()
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()


def create_bimodal_summary_and_plots(df_light, csv_base_path, pdf):
    """
    Create non-normal histogram summary page and individual histogram plots for each non-normal histogram.
    
    Args:
        df_light (pd.DataFrame): Light histogram data
        csv_base_path (Path): Base path to the CSV file (for resolving relative paths)
        pdf: PDF pages object
    """
    # Find non-normal histograms
    non_normal_histograms = detect_non_normal_histograms(df_light, csv_base_path)
    
    if len(non_normal_histograms) == 0:
        # Create a page saying all histograms are normal
        fig = plt.figure(figsize=(11, 8.5))
        fig.suptitle('Non-Normal Distribution Analysis - Light Histograms', fontsize=16, fontweight='bold', y=0.98)
        ax = fig.add_subplot(1, 1, 1)
        ax.axis('off')
        ax.text(0.5, 0.5, 'All light histograms appear to have normal distributions!\nNo deviations detected.', 
               fontsize=14, ha='center', va='center',
               transform=ax.transAxes, 
               bbox=dict(boxstyle='round', facecolor='#90EE90', alpha=0.5))
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()
        return
    
    # Create summary page
    fig = plt.figure(figsize=(11, 8.5))
    fig.suptitle('Non-Normal Distribution Summary - Light Histograms', fontsize=16, fontweight='bold', y=0.98)
    
    # Summary table
    ax_table = fig.add_subplot(1, 1, 1)
    ax_table.axis('off')
    
    # Prepare table data
    table_data = []
    for non_normal in non_normal_histograms:
        peak_str = ', '.join(map(str, non_normal['peak_positions'][:3]))  # Show first 3 peaks
        if len(non_normal['peak_positions']) > 3:
            peak_str += '...'
        reasons_str = '; '.join(non_normal['reasons'][:2])  # Show first 2 reasons
        if len(non_normal['reasons']) > 2:
            reasons_str += '...'
        table_data.append([
            non_normal['serial_number'],
            non_normal['aperture_size'],
            str(non_normal['position']),
            f"{non_normal['weighted_mean']:.2f}",
            reasons_str,
            f"{non_normal['skewness']:.2f}",
            f"{non_normal['kurtosis']:.2f}",
            f"{non_normal['temperature']:.1f}"
        ])
    
    # Create table
    table = ax_table.table(cellText=table_data,
                          colLabels=['Serial Number', 'Aperture', 'Position', 'Weighted Mean', 'Reasons', 'Skewness', 'Kurtosis', 'Temp (°C)'],
                          cellLoc='center',
                          loc='center',
                          bbox=[0, 0, 1, 1])
    
    table.auto_set_font_size(False)
    table.set_fontsize(7)
    table.scale(1, 1.2)
    
    # Style the header
    for i in range(8):
        table[(0, i)].set_facecolor('#9B59B6')  # Purple for non-normal
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    # Highlight rows
    for i in range(len(non_normal_histograms)):
        for j in range(8):
            table[(i + 1, j)].set_facecolor('#E8DAEF')  # Light purple
    
    ax_table.set_title(f'Non-Normal Histograms Detected: {len(non_normal_histograms)}', fontsize=12, fontweight='bold', pad=20)
    
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Create individual histogram plots for each non-normal histogram
    for non_normal in non_normal_histograms:
        # Resolve file path
        relative_path = non_normal['relative_path']
        relative_path_str = str(relative_path).replace('\\', '/')
        file_path = csv_base_path.parent.parent / relative_path_str
        
        # Load histogram
        hist_values, temp, cam_id = load_histogram_from_csv(file_path)
        
        if hist_values is None:
            # Create error page
            fig = plt.figure(figsize=(11, 8.5))
            fig.suptitle(f'Non-Normal: {non_normal["serial_number"]} - {non_normal["aperture_size"]}', 
                        fontsize=14, fontweight='bold')
            ax = fig.add_subplot(1, 1, 1)
            ax.axis('off')
            ax.text(0.5, 0.5, f'Error loading histogram:\n{file_path}', 
                   fontsize=12, ha='center', va='center',
                   transform=ax.transAxes)
            pdf.savefig(fig, bbox_inches='tight')
            plt.close()
            continue
        
        # Create histogram plot with peak markers
        fig, ax = plt.subplots(figsize=(11, 8.5))
        reasons_str = '; '.join(non_normal['reasons'])
        title = f'Non-Normal Distribution: {non_normal["serial_number"]} - {non_normal["aperture_size"]} - Pos {non_normal["position"]}'
        subtitle = f'Mean: {non_normal["weighted_mean"]:.2f}, Skew: {non_normal["skewness"]:.2f}, Kurt: {non_normal["kurtosis"]:.2f}'
        subtitle2 = f'Reasons: {reasons_str}'
        plot_histogram_with_peaks(hist_values, ax, f'{title}\n{subtitle}\n{subtitle2}', 
                                  temp, cam_id, non_normal['weighted_mean'], 
                                  non_normal['peak_positions'])
        
        fig.tight_layout()
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()


def plot_histogram_with_peaks(histogram_values, ax, title, temperature, cam_id, weighted_mean, peak_positions):
    """
    Plot a single histogram with peak positions marked.
    
    Args:
        histogram_values (array): Histogram bin values
        ax: Matplotlib axis
        title (str): Plot title
        temperature (float): Temperature value
        cam_id (int): Camera position
        weighted_mean (float): Weighted mean value
        peak_positions (list): List of peak positions to mark
    """
    bins = np.arange(1024)
    
    # Handle log scale - add small value to avoid log(0)
    hist_log = histogram_values + 1e-6
    
    # Plot histogram
    ax.semilogy(bins, hist_log, 'b-', linewidth=1.5, alpha=0.8)
    ax.fill_between(bins, hist_log, alpha=0.3, color='blue')
    
    # Mark peak positions
    for peak_pos in peak_positions:
        if 0 <= peak_pos < len(hist_log):
            peak_value = hist_log[peak_pos]
            ax.plot(peak_pos, peak_value, 'ro', markersize=10, markeredgecolor='darkred', 
                   markeredgewidth=2, label='Peak' if peak_pos == peak_positions[0] else '')
    
    ax.set_xlabel('Pixel Value (Bin)', fontsize=10)
    ax.set_ylabel('Count (Log Scale)', fontsize=10)
    ax.set_title(title, fontsize=11, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, 1023)
    ax.set_ylim(bottom=1.0)
    
    # Add text with stats
    stats_text = f'Mean: {weighted_mean:.1f}, Temp: {temperature:.1f}°C, Pos: {cam_id + 1}, Peaks: {len(peak_positions)}'
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, 
           fontsize=9, verticalalignment='top',
           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
    # Add legend if peaks are marked
    if peak_positions:
        ax.legend(loc='upper right', fontsize=9)


def create_table_plot(df_stats, title, ax):
    """
    Create a table plot from statistics DataFrame.
    
    Args:
        df_stats (pd.DataFrame): Statistics DataFrame
        title (str): Title for the table
        ax: Matplotlib axis
    """
    ax.axis('tight')
    ax.axis('off')
    
    # Flatten column names
    df_display = df_stats.copy()
    df_display.columns = ['_'.join(col).strip() if col[1] else col[0] for col in df_display.columns]
    
    table = ax.table(cellText=df_display.values,
                    rowLabels=df_display.index.to_list(),
                    colLabels=df_display.columns,
                    cellLoc='center',
                    loc='center',
                    bbox=[0, 0, 1, 1])
    
    table.auto_set_font_size(False)
    table.set_fontsize(7)
    table.scale(1, 1.5)
    
    # Style the header
    for i in range(len(df_display.columns)):
        table[(0, i)].set_facecolor('#4CAF50')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    ax.set_title(title, fontsize=12, fontweight='bold', pad=20)


def plot_skewness_kurtosis_by_aperture(df_light, fig):
    """
    Create boxplots of skewness and kurtosis grouped by aperture size.
    Shows threshold lines on each plot.
    
    Args:
        df_light (pd.DataFrame): Light histogram data with skewness and kurtosis columns
        fig: Matplotlib figure object
    """
    # Filter out rows where skewness or kurtosis is NaN
    df_plot = df_light.dropna(subset=['skewness', 'kurtosis']).copy()
    
    if len(df_plot) == 0:
        ax = fig.add_subplot(1, 1, 1)
        ax.axis('off')
        ax.text(0.5, 0.5, 'No skewness/kurtosis data available for plotting.', 
               fontsize=14, ha='center', va='center',
               transform=ax.transAxes)
        return
    
    apertures = sorted([a for a in df_plot['aperture_size'].unique() if a != "Unknown"])
    
    # Left subplot: Skewness
    ax1 = fig.add_subplot(1, 2, 1)
    data_to_plot_skew = []
    labels_skew = []
    
    for aperture in apertures:
        aperture_data = df_plot[df_plot['aperture_size'] == aperture]['skewness'].values
        if len(aperture_data) > 0:
            data_to_plot_skew.append(aperture_data)
            labels_skew.append(f'{aperture}')
    
    if len(data_to_plot_skew) > 0:
        bp1 = ax1.boxplot(data_to_plot_skew, tick_labels=labels_skew, patch_artist=True, vert=False)
        
        # Color the boxes
        colors = plt.cm.Set3(np.linspace(0, 1, len(bp1['boxes'])))
        for patch, color in zip(bp1['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        # Add data point markers with jitter
        for i, data in enumerate(data_to_plot_skew):
            y_pos = i + 1
            y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
            ax1.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
        
        # Add threshold lines
        ax1.axvline(x=skewness_threshold, color='r', linestyle='--', linewidth=2, 
                   label=f'Threshold: {skewness_threshold}', zorder=4)
        ax1.axvline(x=-skewness_threshold, color='r', linestyle='--', linewidth=2, zorder=4)
    
    ax1.set_xlabel('Skewness', fontsize=10)
    ax1.set_ylabel('Aperture Size', fontsize=10)
    ax1.set_title('Skewness Distribution by Aperture Size (Light)', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='x')
    ax1.legend(loc='best', fontsize=9)
    
    # Right subplot: Kurtosis
    ax2 = fig.add_subplot(1, 2, 2)
    data_to_plot_kurt = []
    labels_kurt = []
    
    for aperture in apertures:
        aperture_data = df_plot[df_plot['aperture_size'] == aperture]['kurtosis'].values
        if len(aperture_data) > 0:
            data_to_plot_kurt.append(aperture_data)
            labels_kurt.append(f'{aperture}')
    
    if len(data_to_plot_kurt) > 0:
        bp2 = ax2.boxplot(data_to_plot_kurt, tick_labels=labels_kurt, patch_artist=True, vert=False)
        
        # Color the boxes
        colors = plt.cm.Set3(np.linspace(0, 1, len(bp2['boxes'])))
        for patch, color in zip(bp2['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        # Add data point markers with jitter
        for i, data in enumerate(data_to_plot_kurt):
            y_pos = i + 1
            y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
            ax2.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
        
        # Add threshold lines for excess kurtosis (kurtosis - 3)
        # We need to show where abs(kurtosis - 3) > kurtosis_threshold
        # So kurtosis > 3 + kurtosis_threshold or kurtosis < 3 - kurtosis_threshold
        ax2.axvline(x=3 + kurtosis_threshold, color='r', linestyle='--', linewidth=2, 
                   label=f'Threshold: ±{kurtosis_threshold} from 3', zorder=4)
        ax2.axvline(x=3 - kurtosis_threshold, color='r', linestyle='--', linewidth=2, zorder=4)
    
    ax2.set_xlabel('Kurtosis', fontsize=10)
    ax2.set_ylabel('Aperture Size', fontsize=10)
    ax2.set_title('Kurtosis Distribution by Aperture Size (Light)', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='x')
    ax2.legend(loc='best', fontsize=9)


def plot_skewness_kurtosis_combined(df_light, fig):
    """
    Create boxplots of skewness and kurtosis for all apertures combined.
    Shows threshold lines on each plot.
    
    Args:
        df_light (pd.DataFrame): Light histogram data with skewness and kurtosis columns
        fig: Matplotlib figure object
    """
    # Filter out rows where skewness or kurtosis is NaN
    df_plot = df_light.dropna(subset=['skewness', 'kurtosis']).copy()
    
    if len(df_plot) == 0:
        ax = fig.add_subplot(1, 1, 1)
        ax.axis('off')
        ax.text(0.5, 0.5, 'No skewness/kurtosis data available for plotting.', 
               fontsize=14, ha='center', va='center',
               transform=ax.transAxes)
        return
    
    # Left subplot: Skewness
    ax1 = fig.add_subplot(1, 2, 1)
    skewness_data = df_plot['skewness'].values
    
    if len(skewness_data) > 0:
        bp1 = ax1.boxplot([skewness_data], tick_labels=['All Apertures'], patch_artist=True, vert=False)
        
        # Color the box
        bp1['boxes'][0].set_facecolor('#4A90E2')
        bp1['boxes'][0].set_alpha(0.7)
        
        # Add data point markers with jitter
        y_pos = 1
        y_jittered = y_pos + np.random.normal(0, 0.05, size=len(skewness_data))
        ax1.scatter(skewness_data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
        
        # Add threshold lines
        ax1.axvline(x=skewness_threshold, color='r', linestyle='--', linewidth=2, 
                   label=f'Threshold: {skewness_threshold}', zorder=4)
        ax1.axvline(x=-skewness_threshold, color='r', linestyle='--', linewidth=2, zorder=4)
    
    ax1.set_xlabel('Skewness', fontsize=10)
    ax1.set_ylabel('Aperture Size', fontsize=10)
    ax1.set_title('Skewness Distribution - All Apertures Combined (Light)', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='x')
    ax1.legend(loc='best', fontsize=9)
    
    # Right subplot: Kurtosis
    ax2 = fig.add_subplot(1, 2, 2)
    kurtosis_data = df_plot['kurtosis'].values
    
    if len(kurtosis_data) > 0:
        bp2 = ax2.boxplot([kurtosis_data], tick_labels=['All Apertures'], patch_artist=True, vert=False)
        
        # Color the box
        bp2['boxes'][0].set_facecolor('#4A90E2')
        bp2['boxes'][0].set_alpha(0.7)
        
        # Add data point markers with jitter
        y_pos = 1
        y_jittered = y_pos + np.random.normal(0, 0.05, size=len(kurtosis_data))
        ax2.scatter(kurtosis_data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
        
        # Add threshold lines for excess kurtosis (kurtosis - 3)
        ax2.axvline(x=3 + kurtosis_threshold, color='r', linestyle='--', linewidth=2, 
                   label=f'Threshold: ±{kurtosis_threshold} from 3', zorder=4)
        ax2.axvline(x=3 - kurtosis_threshold, color='r', linestyle='--', linewidth=2, zorder=4)
    
    ax2.set_xlabel('Kurtosis', fontsize=10)
    ax2.set_ylabel('Aperture Size', fontsize=10)
    ax2.set_title('Kurtosis Distribution - All Apertures Combined (Light)', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='x')
    ax2.legend(loc='best', fontsize=9)


def add_skewness_kurtosis_to_dataframe(df, csv_base_path):
    """
    Calculate skewness and kurtosis for all histograms and add them to the DataFrame.
    This is used to add the columns for plotting.
    
    Args:
        df (pd.DataFrame): Full DataFrame from summary.csv
        csv_base_path (Path): Base path to the CSV file (for resolving relative paths)
        
    Returns:
        pd.DataFrame: DataFrame with skewness and kurtosis columns added
    """
    print("Calculating skewness and kurtosis for all histograms...")
    
    # Initialize columns with NaN values
    if 'skewness' not in df.columns:
        df['skewness'] = np.nan
    if 'kurtosis' not in df.columns:
        df['kurtosis'] = np.nan
    
    # Calculate for each row
    for idx, row in df.iterrows():
        # Skip if already calculated
        if pd.notna(df.at[idx, 'skewness']) and pd.notna(df.at[idx, 'kurtosis']):
            continue
            
        # Resolve file path
        relative_path = row['relative_path']
        relative_path_str = str(relative_path).replace('\\', '/')
        file_path = csv_base_path.parent.parent / relative_path_str
        
        # Load histogram
        hist_values, _, _ = load_histogram_from_csv(file_path)
        
        if hist_values is not None:
            # Calculate skewness and kurtosis
            skewness = calculate_skewness(hist_values)
            kurtosis = calculate_kurtosis(hist_values)
            
            # Update DataFrame
            df.at[idx, 'skewness'] = skewness
            df.at[idx, 'kurtosis'] = kurtosis
        
        # Print progress for every 50 rows
        if (idx + 1) % 50 == 0:
            print(f"  Processed {idx + 1}/{len(df)} rows...")
    
    return df


def add_skewness_kurtosis_to_csv(df, csv_path):
    """
    Save the DataFrame with skewness and kurtosis columns back to the CSV file.
    
    Args:
        df (pd.DataFrame): Full DataFrame with skewness and kurtosis columns
        csv_path (str): Path to the summary.csv file to save
    """
    print(f"Saving updated summary.csv with skewness and kurtosis columns...")
    df.to_csv(csv_path, index=False)
    print(f"Updated summary.csv saved to: {csv_path}")


def generate_pdf_report(csv_path, output_path=None):
    """
    Generate PDF analytics report from summary CSV.
    
    Args:
        csv_path (str): Path to summary.csv
        output_path (str): Optional path for output PDF (default: same directory as CSV)
    """
    csv_file = Path(csv_path)
    if not csv_file.exists():
        print(f"Error: CSV file not found: {csv_path}")
        return
    
    if output_path is None:
        output_path = csv_file.parent / "camera_analytics_report.pdf"
    else:
        output_path = Path(output_path)
    
    print(f"Loading data from: {csv_path}")
    df, df_light, df_dark = load_and_prepare_data(csv_path)
    
    print(f"Found {len(df_light)} light histograms and {len(df_dark)} dark histograms")
    print(f"Aperture sizes: {sorted(df_light['aperture_size'].unique())}")
    print(f"Positions: {sorted(df_light['position'].unique())}")
    
    # Calculate skewness and kurtosis for all histograms (needed for plots and CSV)
    df = add_skewness_kurtosis_to_dataframe(df, csv_file)
    
    # Update df_light and df_dark with calculated values
    df_light = df[df['histogram_type'] == 'light'].copy()
    df_dark = df[df['histogram_type'] == 'dark'].copy()
    
    # Create PDF
    pdf = matplotlib.backends.backend_pdf.PdfPages(output_path)
    
    # Page 1: Overview
    fig = plt.figure(figsize=(11, 8.5))
    fig.suptitle('Camera Test Analytics Report', fontsize=16, fontweight='bold', y=0.98)
    
    # Summary text
    ax_text = fig.add_subplot(1, 1, 1)
    ax_text.axis('off')
    summary_text = f"""
    Data Summary:
    - Total records: {len(df)}
    - Light histograms: {len(df_light)}
    - Dark histograms: {len(df_dark)}
    - Aperture sizes: {', '.join(sorted(df_light['aperture_size'].unique()))}
    - Positions (cam_id): {', '.join(map(str, sorted([p + 1 for p in df_light['position'].unique()])))}
    - Mean weighted mean (light): {df_light['weighted_mean'].mean():.2f}
    - Mean weighted mean (dark): {df_dark['weighted_mean'].mean():.2f}
    """
    ax_text.text(0.1, 0.5, summary_text, fontsize=10, verticalalignment='center',
                family='monospace', transform=ax_text.transAxes)
    
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Page 2: Grouped bar chart
    fig, ax = plt.subplots(figsize=(11, 8.5))
    plot_means_by_aperture_and_position(df_light, df_dark, ax)
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Page 3: Box plot by aperture (light)
    fig, ax = plt.subplots(figsize=(11, 8.5))
    plot_boxplot_by_aperture(df_light, df_dark, ax)
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Page 4: Box plot by aperture (dark)
    fig, ax = plt.subplots(figsize=(11, 8.5))
    plot_boxplot_by_aperture_dark(df_light, df_dark, ax)
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Additional pages: Individual aperture analysis (light histograms only, horizontal boxplots)
    apertures = sorted(df_light['aperture_size'].unique())
    for aperture in apertures:
        if aperture == "Unknown":
            continue
        
        fig, ax = plt.subplots(figsize=(11, 8.5))
        fig.suptitle(f'Aperture Size: {aperture} - Light Histograms', fontsize=14, fontweight='bold')
        
        # Light histogram by position - horizontal boxplot
        light_ap = df_light[df_light['aperture_size'] == aperture]
        positions = sorted(light_ap['position'].unique())
        positions_1indexed = [p + 1 for p in positions]  # 1-indexed for display
        
        # Prepare data for boxplot
        data_to_plot = []
        labels = []
        for pos in positions:
            pos_data = light_ap[light_ap['position'] == pos]['weighted_mean'].values
            if len(pos_data) > 0:
                data_to_plot.append(pos_data)
                labels.append(f'Pos {pos + 1}')  # 1-indexed
        
        # Create horizontal boxplot
        bp = ax.boxplot(data_to_plot, tick_labels=labels, patch_artist=True, vert=False)
        
        # Color the boxes
        colors = plt.cm.Blues(np.linspace(0.4, 0.8, len(bp['boxes'])))
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        
        # Add data point markers with jitter
        for i, data in enumerate(data_to_plot):
            # For horizontal boxplots, y-position is the box number (1-indexed), add jitter
            y_pos = i + 1
            y_jittered = y_pos + np.random.normal(0, 0.05, size=len(data))
            ax.scatter(data, y_jittered, c='black', alpha=0.5, s=20, zorder=3)
        
        ax.set_xlabel('Weighted Mean', fontsize=10)
        ax.set_ylabel('Position (cam_id)', fontsize=10)
        ax.set_title('Distribution of Means by Position', fontsize=12)
        ax.grid(True, alpha=0.3, axis='x')
        
        fig.tight_layout(rect=[0, 0, 1, 0.96])
        pdf.savefig(fig, bbox_inches='tight')
        plt.close()
    
    # Outlier analysis pages at the end
    create_outlier_summary_and_plots(df_light, csv_file, pdf)
    
    # Bimodal distribution analysis pages at the end
    create_bimodal_summary_and_plots(df_light, csv_file, pdf)
    
    # Page: Skewness and Kurtosis by Aperture Size
    fig = plt.figure(figsize=(11, 8.5))
    fig.suptitle('Skewness and Kurtosis Analysis by Aperture Size', fontsize=16, fontweight='bold', y=0.98)
    plot_skewness_kurtosis_by_aperture(df_light, fig)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    # Page: Skewness and Kurtosis - All Apertures Combined
    fig = plt.figure(figsize=(11, 8.5))
    fig.suptitle('Skewness and Kurtosis Analysis - All Apertures Combined', fontsize=16, fontweight='bold', y=0.98)
    plot_skewness_kurtosis_combined(df_light, fig)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    pdf.savefig(fig, bbox_inches='tight')
    plt.close()
    
    pdf.close()
    print(f"\nPDF report saved to: {output_path}")
    
    # Save updated summary.csv with skewness and kurtosis columns
    add_skewness_kurtosis_to_csv(df, csv_path)


def main():
    """Main function to handle command line arguments."""
    if len(sys.argv) < 2:
        print("Usage: python analyze_camera_analytics.py <summary_csv_path> [output_pdf_path]")
        print("Example: python analyze_camera_analytics.py qisda_data/output/summary.csv")
        sys.exit(1)
    
    csv_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    generate_pdf_report(csv_path, output_path)


if __name__ == "__main__":
    main()

